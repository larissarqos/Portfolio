import streamlit as st
import pandas as pd
import joblib
import matplotlib.pyplot as plt
from wordcloud import WordCloud
from sklearn.feature_extraction.text import CountVectorizer
import nltk
import re

# - Pr√©-processamento de texto
nltk.download('stopwords')
from nltk.corpus import stopwords
stopwords_pt = set(stopwords.words('portuguese'))

def limpar_texto(texto):
    texto = re.sub(r'[^a-zA-Z√Ä-√ø\s]', '', str(texto))
    texto = texto.lower()
    palavras = texto.split()
    palavras = [p for p in palavras if p not in stopwords_pt]
    return ' '.join(palavras)

# -- Carregamento do modelo e vetor
modelo = joblib.load('modelo_logistico.pkl')
vetor = joblib.load('vetor_countvectorizer.pkl')

# -- Sidebar
st.sidebar.title("Menu")
opcao = st.sidebar.radio("Escolha uma op√ß√£o:", ["Gerar Nuvem de Palavras", "Analisar Avalia√ß√£o"])

# -- T√≠tulo e descri√ß√£o do app
st.markdown("<h1 style='text-align: center;'>üí¨ An√°lise de Sentimentos</h1>", unsafe_allow_html=True)
st.markdown("<p style='text-align: center;'><i>App de an√°lise de sentimentos em avalia√ß√µes de produtos</i></p>", unsafe_allow_html=True)
st.divider()

# -- Op√ß√£o: Ver nuvens de palavras
if opcao == "Gerar Nuvem de Palavras":
    st.markdown("Fa√ßa o upload de um arquivo .csv com avalia√ß√µes para gerar a nuvem de palavras")
    arquivo = st.file_uploader("Fazer upload do arquivo CSV", type=["csv"])

    if arquivo is not None:
        try:
            df = pd.read_csv(arquivo, encoding='utf-8', on_bad_lines='skip')
        except Exception as e:
            st.error(f"Erro ao ler o arquivo CSV: {e}")
            st.stop()

        st.write("Pr√©via dos dados:")
        st.dataframe(df.head())

        df = df.dropna(subset=['review_comment_message'])
        df['texto_limpo'] = df['review_comment_message'].apply(limpar_texto)

        if st.button("Gerar Nuvem de Palavras"):
            from sklearn.feature_extraction.text import CountVectorizer

            stopwords_pt_lista = list(stopwords_pt)

            def gerar_ngrams(textos, n=3):
                vectorizer = CountVectorizer(ngram_range=(1, n), stop_words=stopwords_pt_lista)
                X = vectorizer.fit_transform(textos)
                soma = X.sum(axis=0)
                frequencias = {palavra: soma[0, idx] for palavra, idx in vectorizer.vocabulary_.items()}
                return frequencias

            frequencias = gerar_ngrams(df['texto_limpo'], n=3)

            st.divider()
            st.markdown("<h3 style='text-align: center;'>Nuvem de Palavras das Avalia√ß√µes</h3>", unsafe_allow_html=True)
            wordcloud = WordCloud(width=1200, height=800, background_color='black').generate_from_frequencies(frequencias)
            fig, ax = plt.subplots()
            ax.imshow(wordcloud, interpolation='bilinear')
            ax.axis("off")
            st.pyplot(fig)


# -- Op√ß√£o: Analisar Avalia√ß√£o
elif opcao == "Analisar Avalia√ß√£o":
    st.markdown("<h4>Digite uma avalia√ß√£o para an√°lise</h4>", unsafe_allow_html=True)
    frase = st.text_input("", placeholder="Exemplo: Gostei muito do produto, chegou r√°pido e bem embalado")
    
    st.markdown("")
    
    if st.button("Analisar") and frase:
        frase_limpa = limpar_texto(frase)
        frase_vetor = vetor.transform([frase_limpa])
        predicao = modelo.predict(frase_vetor)[0]
        if predicao == 1:
            sentimento = "Avalia√ß√£o Positiva üòä"
            st.success(sentimento)
        else:
            sentimento = "Avalia√ß√£o Negativa üòû"
            st.error(sentimento)
        